{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7532b0e5-e766-4b9d-847a-98779d97da9e",
   "metadata": {},
   "source": [
    "# Differences between LangGraph and AgentExecutor\n",
    "\n",
    "Here we compare functionality between LangGraph's pre-built agent executors and LangChain's [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html) class.\n",
    "\n",
    "LangGraph supports multiple types of pre-built agent executors, including [`agent_executor`](https://github.com/langchain-ai/langgraph/blob/main/langgraph/prebuilt/agent_executor.py) and `chat_agent_executor`. `agent_executor`, like LangChain's AgentExecutor, is not on its own conversational; the agent iterates by updating actions and observations to an \"agent scratchpad\" in its prompt. `chat_agent_executor` is naturally conversational, and includes agent actions, tool results, and user messages in its prompt. We focus on LangGraph's `chat_agent_executor` for most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d43b5e-4991-452d-885c-2729a16ed391",
   "metadata": {},
   "source": [
    "## 0. Basic usage\n",
    "\n",
    "First we define a model and a tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "561d539d-9398-4b84-81b1-0c300d4b7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "\n",
    "query = \"what is the value of magic_function(3)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37e6b8-0f35-4249-b97a-cf3de815c079",
   "metadata": {},
   "source": [
    "For AgentExecutor, we define a prompt with a placeholder for the agent's scratchpad. The agent can be invoked as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f70fae3-25a6-4487-ac81-420f8e49049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of magic_function(3) is 5.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303d322-1069-4655-b8de-35367a22db89",
   "metadata": {},
   "source": [
    "LangGraph's `chat_agent_executor` manages a state that is defined by a list of messages. It will continue to process the list until there are no tool calls in the agent's output. To kick it off, we input a list of messages. The output will contain the entire state of the graph-- in this case, the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a9c97cc-b92d-4112-818e-62706c82be8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of magic_function(3) is 5.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import chat_agent_executor\n",
    "\n",
    "app = chat_agent_executor.create_tool_calling_executor(model, tools)\n",
    "\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57ddf6-2c23-4720-9e39-c0a932bafd98",
   "metadata": {},
   "source": [
    "Note that we can easily continue the conversation by appending a new message to the list and invoking the agent again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e873fc9-dcac-47d1-9b40-c9aeeb92dcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Pardon?',\n",
       " 'output': 'Apologies for the confusion. The value of magic_function(3) is 5.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history = messages[\"messages\"]\n",
    "\n",
    "new_query = \"Pardon?\"\n",
    "\n",
    "messages = app.invoke({\"messages\": message_history + [(\"human\", new_query)]})\n",
    "{\n",
    "    \"input\": new_query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35744ef9-1373-4778-a796-70318474e4b9",
   "metadata": {},
   "source": [
    "## 1. Visibility\n",
    "\n",
    "### `verbose`\n",
    "\n",
    "AgentExecutor supports a `verbose` flag that will log intermediate steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89197e2b-ffc1-4499-bb47-e008b0a2248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `magic_function` with `{'input': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThe value of the magic function for input 3 is 5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of the magic function for input 3 is 5.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828567d-f212-42ec-bb50-fc19ba1c8e77",
   "metadata": {},
   "source": [
    "We can use LangGraph's streaming capabilities to provide similar visibility as toggling `AgentExecutor.verbose`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c257ba-59b0-4d0d-8585-ac4bfdadd799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking: [{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_xVw6xlkOdKJ3I49PnxfqIB9W'}]\n",
      "------\n",
      "5\n",
      "------\n",
      "The value of magic_function(3) is 5.\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "def print_chunk(chunk: dict) -> None:\n",
    "    if \"agent\" in chunk:\n",
    "        message = chunk[\"agent\"][\"messages\"][0]\n",
    "        if message.tool_calls:\n",
    "            print(f\"Invoking: {message.tool_calls}\")\n",
    "        else:\n",
    "            print(message.content)\n",
    "    elif \"action\" in chunk:\n",
    "        print(chunk[\"action\"][\"messages\"][0].content)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "for chunk in app.stream({\"messages\": [(\"human\", query)]}):\n",
    "    print_chunk(chunk)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b9430c-0463-4e6f-b383-61c47dbc76bf",
   "metadata": {},
   "source": [
    "### `return_intermediate_steps`\n",
    "\n",
    "Setting this parameter on AgentExecutor allows users to access `intermediate_steps`, which pairs agent actions (e.g., tool invocations) with their outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd2b4eb-43da-45b7-bd77-d92760e817a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_lP8T6vxJxgmQZjMuVfV97hSZ', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-9ab5dce0-3b13-4985-9a1b-6f6029cb8f51', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_lP8T6vxJxgmQZjMuVfV97hSZ'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_lP8T6vxJxgmQZjMuVfV97hSZ', 'index': 0}])], tool_call_id='call_lP8T6vxJxgmQZjMuVfV97hSZ'), 5)]\n"
     ]
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)\n",
    "result = agent_executor.invoke({\"input\": query})\n",
    "print(result[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a69b2-2138-44d5-bbb9-79fbc37b609f",
   "metadata": {},
   "source": [
    "By default LangGraph lets you access any key in the state. Because LangGraph's `agent_executor` includes `intermediate_steps` in the state, we can easily replicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c573dff1-f710-48fe-a023-0a443e27a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XF03NA8iH75B0pQoJ5Zau2zA', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 71, 'total_tokens': 85}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8aee9f68-386a-49d7-b14c-247a25fc9ea9-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_XF03NA8iH75B0pQoJ5Zau2zA'}])], tool_call_id='call_XF03NA8iH75B0pQoJ5Zau2zA'), '5')]\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_agent_executor\n",
    "\n",
    "\n",
    "agent_executor_app = create_agent_executor(agent, tools)\n",
    "\n",
    "result = agent_executor_app.invoke({\"input\": query})\n",
    "print(result[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77896e-a34f-4437-a539-a56cd30baf0a",
   "metadata": {},
   "source": [
    "## 2. Limiting iterations\n",
    "\n",
    "### `max_iterations`\n",
    "`AgentExecutor` implements a `max_iterations` parameter, whereas this is controlled via `recursion_limit` in LangGraph.\n",
    "\n",
    "Note that in AgentExecutor, an \"iteration\" includes a full turn of tool invocation and execution. In LangGraph, each step contributes to the recursion limit, so we will need to multiply by two (and add one) to get equivalent results.\n",
    "\n",
    "If the recursion limit is reached, LangGraph raises a specific exception type, that we can catch and manage similarly to AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727fdff3-70b1-4e95-a6bd-8e540b21916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def magic_function(input: str) -> str:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return \"Sorry, there was an error. Please try again.\"\n",
    "\n",
    "\n",
    "tools = [magic_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c9600f-4cb0-4749-8f5f-bafc161b3119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `magic_function` with `{'input': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSorry, there was an error. Please try again.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `magic_function` with `{'input': '3'}`\n",
      "responded: It seems there was an error when trying to calculate the value of `magic_function(3)`. Let me try again.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSorry, there was an error. Please try again.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `magic_function` with `{'input': '3'}`\n",
      "responded: It seems there is still an error when trying to calculate the value of `magic_function(3)`. Let me try a different approach to resolve this.\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSorry, there was an error. Please try again.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'Agent stopped due to max iterations.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0e70b9-2703-471e-ba82-d61432554fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking: [{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_VO1j6VY5eeQQLiZSGQk9Us1v'}]\n",
      "------\n",
      "Sorry, there was an error. Please try again.\n",
      "------\n",
      "Invoking: [{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_CftpdWmI650c4gDI7CzG8MfQ'}]\n",
      "------\n",
      "Sorry, there was an error. Please try again.\n",
      "------\n",
      "Invoking: [{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_vXQLVE014FblqOiyxdYU9wJc'}, {'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_eVSaLAThLLIkxw2EepNhPZuI'}]\n",
      "------\n",
      "Sorry, there was an error. Please try again.\n",
      "------\n",
      "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.pregel import GraphRecursionError\n",
    "\n",
    "\n",
    "app = chat_agent_executor.create_tool_calling_executor(model, tools)\n",
    "\n",
    "try:\n",
    "    for chunk in app.stream({\"messages\": [(\"human\", query)]}, {\"recursion_limit\": 2*3 + 1}):\n",
    "        print_chunk(chunk)\n",
    "        print(\"------\")\n",
    "except GraphRecursionError:\n",
    "    print(\n",
    "        {\"input\": query, \"output\": \"Agent stopped due to max iterations.\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad06d5-9ca0-435a-8fa5-e1d1791891f6",
   "metadata": {},
   "source": [
    "### `max_execution_time`\n",
    "\n",
    "`AgentExecutor` implements a `max_execution_time` parameter, allowing users to abort a run that exceeds a total time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a75a20-a606-4ba6-b821-8bb2ae30f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@tool\n",
    "def magic_function(input: str) -> str:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    time.sleep(2.5)\n",
    "    return \"Sorry, there was an error. Please try again.\"\n",
    "\n",
    "\n",
    "tools = [magic_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5c0e13-a247-45a8-987e-d751b35fe1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `magic_function` with `{'input': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSorry, there was an error. Please try again.\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'Agent stopped due to max iterations.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    max_execution_time=2,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2f310-e60d-45eb-982a-e96fdd4a70b1",
   "metadata": {},
   "source": [
    "LangGraph does not support constraints on the total execution time, but you can implement constraints on the duration of any individual step using `step_timeout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b45aa1d3-5134-47da-bf37-3f1d271fa2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking: [{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_yxIZQiBkDn6YsMqw6PKTAmCy'}]\n",
      "------\n",
      "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}\n"
     ]
    }
   ],
   "source": [
    "app = chat_agent_executor.create_tool_calling_executor(model, tools)\n",
    "app.step_timeout = 2\n",
    "\n",
    "try:\n",
    "    for chunk in app.stream({\"messages\": [(\"human\", query)]}):\n",
    "        print_chunk(chunk)\n",
    "        print(\"------\")\n",
    "except TimeoutError:\n",
    "    print(\n",
    "        {\"input\": query, \"output\": \"Agent stopped due to max iterations.\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a4b01-3556-4150-a7a3-20f033852bed",
   "metadata": {},
   "source": [
    "## 3. Handling errors\n",
    "\n",
    "Note: pending https://github.com/langchain-ai/langgraph/pull/319\n",
    "\n",
    "When using tool-calling models, both LangGraph's built-in `create_tool_calling_executor` and AgentExecutor support handling of parsing errors.\n",
    "\n",
    "Below, we construct a model whose first response includes a malformed tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c7761d-bcfd-4b07-a503-c1023a87e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac6e19e9-3d27-4291-8db3-8b82374d3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "\n",
    "class ErrorProneModel(ChatOpenAI):\n",
    "\n",
    "    first_message = True\n",
    "\n",
    "    message = AIMessageChunk(\n",
    "        content=\"\",\n",
    "        additional_kwargs={\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": \"abc123\",\n",
    "                    \"function\": {\n",
    "                        \"arguments\": \"oops\",  # <-- malformed JSON\n",
    "                        \"name\": \"magic_function\",\n",
    "                    },\n",
    "                    \"type\": \"function\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        **kwargs\n",
    "    ) -> List[ChatGenerationChunk]:\n",
    "        if self.first_message:\n",
    "            self.first_message = False\n",
    "            return [ChatGenerationChunk(message=self.message)]\n",
    "        else:\n",
    "            return super()._stream(messages, **kwargs)\n",
    "\n",
    "    def _generate(self, messages: List[BaseMessage], **kwargs) -> ChatResult:\n",
    "        if self.first_message:\n",
    "            self.first_message = False\n",
    "            return ChatResult(generations=[ChatGeneration(message=self.message)])\n",
    "        else:\n",
    "            return super()._generate(messages, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9cce55-6fdd-4af0-90dd-e84f794c827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of `magic_function(3)` is 5.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_tool_calling_agent(ErrorProneModel(), tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58841e0f-6b7f-47df-a80b-8c87e3092bc6",
   "metadata": {},
   "source": [
    "AgentExecutor will retry upon parsing failures if `handle_parsing_errors` is set. See [Langsmith trace](https://smith.langchain.com/public/6f2bc739-16f4-4a52-80b6-772b3439cece/r) for the above run.\n",
    "\n",
    "In LangGraph, we can pass in an arbitrary function that, given the message with malformed tool calls, appends new messages\n",
    "for the agent to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ff6632a-4faa-4ec4-8144-71a0e333a2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the value of magic_function(3)?',\n",
       " 'output': 'The value of the magic_function(3) is 5.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "def handle_error_function(offending_message: AIMessage) -> list:\n",
    "    tool_call_id = offending_message.additional_kwargs[\"tool_calls\"][0][\"id\"]\n",
    "    return [\n",
    "        ToolMessage(content=\"error\", tool_call_id=tool_call_id),\n",
    "        HumanMessage(content=\"There was an error, please try the tool again.\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "app = chat_agent_executor.create_tool_calling_executor(\n",
    "    ErrorProneModel(),\n",
    "    tools,\n",
    "    handle_parsing_errors=handle_error_function,\n",
    ")\n",
    "\n",
    "\n",
    "messages = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "{\n",
    "    \"input\": query,\n",
    "    \"output\": messages[\"messages\"][-1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ab9b7-990c-4c39-b149-b4ef3f925ea8",
   "metadata": {},
   "source": [
    "See [Langsmith trace](https://smith.langchain.com/public/3986680c-17dc-48a3-ba32-eac7e6745b38/r) for the above run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
