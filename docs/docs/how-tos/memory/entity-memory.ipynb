{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aed9b90-b9f1-4345-a0bf-389ec8eda39e",
   "metadata": {},
   "source": [
    "# How to add memory of named entities\n",
    "\n",
    "One strategy for managing long conversation histories is to restrict what information is stored \"long-term\". For example, instead of storing messages verbatim, an application can persist selected facts that it learns during the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61b5837-0b2d-4da5-9c63-5c8e44688861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables.config import ensure_config\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class KnowledgeTriple(TypedDict):\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object_: str\n",
    "\n",
    "\n",
    "vector_store = InMemoryVectorStore(OpenAIEmbeddings())\n",
    "\n",
    "@tool\n",
    "def update_knowledge_store(knowledge_triple: KnowledgeTriple) -> None:\n",
    "    \"\"\"Add a new knowledge triple to the knowledge store.\"\"\"\n",
    "    serialized = \" \".join(knowledge_triple.values())\n",
    "    config_dict = ensure_config()\n",
    "    user_id = config_dict[\"configurable\"].get(\"user_id\")\n",
    "    document = Document(\n",
    "        serialized,\n",
    "        metadata={\n",
    "            \"subject\": knowledge_triple[\"subject\"],\n",
    "            \"user_id\": user_id,\n",
    "        },\n",
    "    )\n",
    "    vector_store.add_documents([document])\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_knowledge(query: str) -> str:\n",
    "    \"\"\"Fetch facts from the knowledge store.\"\"\"\n",
    "    config_dict = ensure_config()\n",
    "    user_id = config_dict[\"configurable\"].get(\"user_id\")\n",
    "    def _filter_function(doc: Document) -> bool:\n",
    "        return doc.metadata.get(\"user_id\") == user_id\n",
    "\n",
    "    documents = vector_store.similarity_search(\n",
    "        query, k=3, filter=_filter_function\n",
    "    )\n",
    "    return \"\\n\\n\".join(document.page_content for document in documents)\n",
    "\n",
    "\n",
    "tools = [update_knowledge_store, fetch_knowledge]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a friendly assistant. When you are told a fact about a person,\n",
    "use the `update_knowledge_store` tool to store that fact via a\n",
    "subject, predicate, object triple.\n",
    "\n",
    "Only update the knowledge store if you are told a material fact.\n",
    "\n",
    "If you require facts about a person to answer a query, use the\n",
    "`fetch_knowledge` tool to retrieve relevant facts.\n",
    "\"\"\"\n",
    "\n",
    "app = create_react_agent(llm, tools, state_modifier=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cee7be4-b99e-404e-9fa0-988365fdcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi I'm Alice, how are you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Alice! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\", \"user_id\": \"user_1\"}}\n",
    "query = \"Hi I'm Alice, how are you?\"\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74d0595-1e34-41e8-9fc7-c61190b3a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have your name yet. If you tell me, I can remember it for you!\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e96141-1293-4d5b-be19-172e3dbb215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Bob likes apples.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_knowledge_store (call_nYa8eaRfzsfzQ5p1iBnniprv)\n",
      " Call ID: call_nYa8eaRfzsfzQ5p1iBnniprv\n",
      "  Args:\n",
      "    knowledge_triple: {'subject': 'Bob', 'predicate': 'likes', 'object_': 'apples'}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_knowledge_store\n",
      "\n",
      "null\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've stored the fact that Bob likes apples. If you have more information or questions, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "query = \"Bob likes apples.\"\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d87d91-36e0-4cea-8432-8f0672cae64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What does Bob like to eat?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_knowledge (call_mxnUxjOw2PVRfi5lVNgWMC8e)\n",
      " Call ID: call_mxnUxjOw2PVRfi5lVNgWMC8e\n",
      "  Args:\n",
      "    query: Bob\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_knowledge\n",
      "\n",
      "Bob likes apples\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bob likes apples.\n"
     ]
    }
   ],
   "source": [
    "query = \"What does Bob like to eat?\"\n",
    "\n",
    "input_messages = [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d318811-5109-49ed-99ba-cad05af2a455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bd7486ee-cb8e-4167-ae2b-ef973aa0bb90', metadata={'subject': 'Bob', 'user_id': 'user_1'}, page_content='Bob likes apples')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967a5ddc-f3fb-4f3e-9432-f833c47cd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, trim_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "def state_modifier(state) -> list[BaseMessage]:\n",
    "    \"\"\"Given the agent state, return a list of messages for the chat model.\"\"\"\n",
    "    return trim_messages(\n",
    "        state[\"messages\"],\n",
    "        token_counter=len,  # specifying `len` will count messages\n",
    "        max_tokens=4,  # retain up to 5 messages.\n",
    "        strategy=\"last\",\n",
    "        start_on=(\"human\", \"ai\"),\n",
    "        include_system=True,\n",
    "        allow_partial=False,\n",
    "    )\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "app = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    state_modifier=state_modifier,\n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12d032c-c89a-41cb-902e-f26a5f9509e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Bob is my friend.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  update_knowledge_store (call_75RzxpGDvU53vVovS4aImKUv)\n",
      " Call ID: call_75RzxpGDvU53vVovS4aImKUv\n",
      "  Args:\n",
      "    knowledge_triple: {'subject': 'Bob', 'predicate': 'is a friend of', 'object_': 'User'}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_knowledge_store\n",
      "\n",
      "null\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've stored the fact that Bob is your friend. If you have more information about Bob or anyone else, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\", \"user_id\": \"user_1\"}}\n",
    "\n",
    "prior_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Bob likes apples.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Nice, good to know.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Four.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Thanks.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"You're welcome!\"},\n",
    "]\n",
    "\n",
    "query = \"Bob is my friend.\"\n",
    "\n",
    "input_messages = prior_messages + [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d336056d-a565-4c49-be4c-eafcdcf10d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What does my friend like to eat? Use the tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_knowledge (call_tN1mBQgAzJ16lXZ3jQPhHQGk)\n",
      " Call ID: call_tN1mBQgAzJ16lXZ3jQPhHQGk\n",
      "  Args:\n",
      "    query: friend likes to eat\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_knowledge\n",
      "\n",
      "Bob likes apples\n",
      "\n",
      "Bob is a friend of User\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your friend Bob likes to eat apples.\n"
     ]
    }
   ],
   "source": [
    "query = \"What does my friend like to eat? Use the tool.\"\n",
    "\n",
    "input_messages = prior_messages + [{\"role\": \"user\", \"content\": query}]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
